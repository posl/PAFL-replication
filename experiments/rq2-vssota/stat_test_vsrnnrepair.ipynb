{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys, glob\n",
    "import argparse\n",
    "# 異なる階層のutilsをインポートするために必要\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict\n",
    "# 異なる階層のutilsからインポート\n",
    "from utils.constant import *\n",
    "from utils.help_func import load_pickle, save_pickle, load_json, save_json\n",
    "# 異なる階層のmodel_utilsからインポート\n",
    "from model_utils.model_util import load_model, sent2tensor\n",
    "from model_utils import train_args\n",
    "from utils.constant import *\n",
    "from utils.stat_util import *\n",
    "from utils.help_func import load_pickle\n",
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "variants = ['srnn', 'gru', 'lstm']\n",
    "thetas = [10, 50]\n",
    "method_names = ['ochiai', 'tarantula', 'dstar', 'ochiai2', 'ample']\n",
    "num_dataset = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# methodごとに検定結果をまとめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------method=ochiai------\n",
      "0.06\n",
      "0.1\n",
      "0.02\n",
      "187 288 0.6493055555555556\n",
      "187 560\n",
      "------method=tarantula------\n",
      "0.13\n",
      "0.15\n",
      "198 288 0.6875\n",
      "198 559\n",
      "------method=dstar------\n",
      "0.07\n",
      "0.06\n",
      "0.02\n",
      "178 288 0.6180555555555556\n",
      "178 560\n",
      "------method=ochiai2------\n",
      "0.1\n",
      "0.07\n",
      "213 288 0.7395833333333334\n",
      "213 560\n",
      "------method=ample------\n",
      "0.06\n",
      "0.06\n",
      "185 288 0.6423611111111112\n",
      "185 559\n"
     ]
    }
   ],
   "source": [
    "res_arr = np.zeros((len(method_names), B, 3*2*8, 6*2))\n",
    "stat_res_arr = np.full((len(method_names), 3*2*8, 6), False)\n",
    "for mi, method in enumerate(method_names):\n",
    "  print(f'------method={method}------')\n",
    "  for bi in range(B):\n",
    "    pafl_path = f'./artifacts/pafl_res_fortest/boot_{bi}/{method}_pafl_res.csv'\n",
    "    rnnrepair_path = f'./artifacts/rnnrepair_res_fortest/boot_{bi}_res.csv'\n",
    "    pafl_res = np.genfromtxt(pafl_path, delimiter=',', dtype='float').astype(np.float32)\n",
    "    rnnrepair_res = np.genfromtxt(rnnrepair_path, delimiter=',', dtype='float').astype(np.float32)\n",
    "    res_arr[mi][bi][:, :6] = pafl_res\n",
    "    res_arr[mi][bi][:, 6:] = rnnrepair_res  \n",
    "  cnt, err_cnt = 0, 0\n",
    "  for i, elei in enumerate(stat_res_arr[mi]):\n",
    "    for j, _ in enumerate(elei):\n",
    "      pafl_group = res_arr[mi, :, i, j]\n",
    "      rnnrepair_group = res_arr[mi, :, i, j+6]\n",
    "      try:\n",
    "        p_value = stats.mannwhitneyu(pafl_group, rnnrepair_group, alternative=\"less\").pvalue\n",
    "        p_value = round(p_value, 4)\n",
    "      except ValueError as e:\n",
    "        # print(e)\n",
    "        # print(pafl_group, rnnrepair_group)\n",
    "        err_cnt += 1\n",
    "        continue\n",
    "      u = stats.mannwhitneyu(pafl_group, rnnrepair_group, alternative=\"less\").statistic\n",
    "      d_cliff = - (2*u/(len(pafl_group)*len(rnnrepair_group)) - 1)\n",
    "      d_cliff = round(d_cliff, 4)\n",
    "      if np.mean(pafl_group) >= np.mean(rnnrepair_group):\n",
    "        if d_cliff > 0:\n",
    "          print(d_cliff)\n",
    "      # p<0.01かつd_cliff>0474のを記憶\n",
    "      if p_value < 0.01 and d_cliff > 0.474:\n",
    "        cnt += 1\n",
    "        stat_res_arr[mi][i][j] = True\n",
    "  # print(err_cnt, 3*2*8*6*2) # 128 576\n",
    "  print(cnt, 3*2*8*6, cnt/(3*2*8*6))\n",
    "  # print(np.count_nonzero(stat_res_arr[mi]))\n",
    "  print(cnt, 3*2*8*6*2-err_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset, variantごとに検定結果をまとめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10, 48, 12)\n",
      "(5, 48, 6)\n"
     ]
    }
   ],
   "source": [
    "print(res_arr.shape) # (method, boot, theta*variant*dataset, metrics*2)\n",
    "print(stat_res_arr.shape) # (method, theta*variant*dataset, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットごとに見るには，\n",
    "\n",
    "stat_res_arrを `(dataset, theta*variant*method, metrics)` にかえればいい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "deno = len(thetas) * 6 * len(method_names)\n",
    "datasets = ['3', '4', '7', 'bp', 'mr', 'imdb', 'toxic', 'mnist']\n",
    "dic_per_ds_variant = defaultdict(defaultdict)\n",
    "for di, dataset in enumerate(datasets):\n",
    "  dic_per_ds_variant[dataset] = defaultdict(float)\n",
    "  for vi, variant in enumerate(variants):\n",
    "    for mi, method in enumerate(method_names):\n",
    "      # theta=10, 50の場合のカウントを足す(dataset, variantごとに)\n",
    "      offs = 16 * vi\n",
    "      dic_per_ds_variant[dataset][variant] += (np.count_nonzero(stat_res_arr[mi][di+offs]) + \\\n",
    "                                                np.count_nonzero(stat_res_arr[mi][di+8+offs])) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "defaultdict(collections.defaultdict,\n            {'3': defaultdict(float,\n                         {'srnn': 0.8666666666666666,\n                          'gru': 0.7833333333333333,\n                          'lstm': 0.3666666666666667}),\n             '4': defaultdict(float,\n                         {'srnn': 0.4666666666666667,\n                          'gru': 0.3666666666666667,\n                          'lstm': 0.5666666666666667}),\n             '7': defaultdict(float,\n                         {'srnn': 0.3333333333333333,\n                          'gru': 0.5666666666666667,\n                          'lstm': 0.8666666666666667}),\n             'bp': defaultdict(float,\n                         {'srnn': 0.23333333333333334,\n                          'gru': 0.3333333333333333,\n                          'lstm': 0.2833333333333333}),\n             'mr': defaultdict(float,\n                         {'srnn': 0.7999999999999999,\n                          'gru': 0.8166666666666667,\n                          'lstm': 0.7333333333333333}),\n             'imdb': defaultdict(float,\n                         {'srnn': 0.8333333333333334,\n                          'gru': 0.75,\n                          'lstm': 0.5333333333333333}),\n             'toxic': defaultdict(float,\n                         {'srnn': 0.8666666666666666,\n                          'gru': 0.8999999999999999,\n                          'lstm': 0.8333333333333333}),\n             'mnist': defaultdict(float,\n                         {'srnn': 1.0,\n                          'gru': 1.0,\n                          'lstm': 0.9166666666666666})})"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_per_ds_variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method, variantごとに検定結果をまとめる\n",
    "もうわけわかんねーや＾＾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['3', '4', '7', 'bp', 'mr', 'imdb', 'toxic', 'mnist']\n",
    "deno = len(thetas) * 6 * len(datasets)\n",
    "dic_per_me_variant = defaultdict(defaultdict)\n",
    "\n",
    "for mi, method in enumerate(method_names):\n",
    "  dic_per_me_variant[method] = defaultdict(float)\n",
    "  for vi, variant in enumerate(variants):\n",
    "    for di, dataset in enumerate(datasets):\n",
    "      # theta=10, 50の場合のカウントを足す(dataset, variantごとに)\n",
    "      offs = 16 * vi\n",
    "      dic_per_me_variant[method][variant] += (np.count_nonzero(stat_res_arr[mi][di+offs]) + \\\n",
    "                                                np.count_nonzero(stat_res_arr[mi][di+8+offs])) / deno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "defaultdict(collections.defaultdict,\n            {'ochiai': defaultdict(float,\n                         {'srnn': 0.6354166666666666,\n                          'gru': 0.6875,\n                          'lstm': 0.625}),\n             'tarantula': defaultdict(float,\n                         {'srnn': 0.71875,\n                          'gru': 0.6979166666666667,\n                          'lstm': 0.6458333333333334}),\n             'dstar': defaultdict(float,\n                         {'srnn': 0.6145833333333333,\n                          'gru': 0.65625,\n                          'lstm': 0.5833333333333334}),\n             'ochiai2': defaultdict(float,\n                         {'srnn': 0.8020833333333334,\n                          'gru': 0.7291666666666667,\n                          'lstm': 0.6875}),\n             'ample': defaultdict(float,\n                         {'srnn': 0.6041666666666666,\n                          'gru': 0.6770833333333334,\n                          'lstm': 0.6458333333333333})})"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_per_me_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>3</th>\n      <th>4</th>\n      <th>7</th>\n      <th>bp</th>\n      <th>mr</th>\n      <th>imdb</th>\n      <th>toxic</th>\n      <th>mnist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>srnn</th>\n      <td>0.866667</td>\n      <td>0.466667</td>\n      <td>0.333333</td>\n      <td>0.233333</td>\n      <td>0.800000</td>\n      <td>0.833333</td>\n      <td>0.866667</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>gru</th>\n      <td>0.783333</td>\n      <td>0.366667</td>\n      <td>0.566667</td>\n      <td>0.333333</td>\n      <td>0.816667</td>\n      <td>0.750000</td>\n      <td>0.900000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>lstm</th>\n      <td>0.366667</td>\n      <td>0.566667</td>\n      <td>0.866667</td>\n      <td>0.283333</td>\n      <td>0.733333</td>\n      <td>0.533333</td>\n      <td>0.833333</td>\n      <td>0.916667</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             3         4         7        bp        mr      imdb     toxic  \\\nsrnn  0.866667  0.466667  0.333333  0.233333  0.800000  0.833333  0.866667   \ngru   0.783333  0.366667  0.566667  0.333333  0.816667  0.750000  0.900000   \nlstm  0.366667  0.566667  0.866667  0.283333  0.733333  0.533333  0.833333   \n\n         mnist  \nsrnn  1.000000  \ngru   1.000000  \nlstm  0.916667  "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_per_ds = pd.DataFrame.from_dict(dic_per_ds_variant)\n",
    "display(df_per_ds)\n",
    "np.savetxt('./stat_res_per_ds.csv', df_per_ds.values, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ochiai</th>\n      <th>tarantula</th>\n      <th>dstar</th>\n      <th>ochiai2</th>\n      <th>ample</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>srnn</th>\n      <td>0.635417</td>\n      <td>0.718750</td>\n      <td>0.614583</td>\n      <td>0.802083</td>\n      <td>0.604167</td>\n    </tr>\n    <tr>\n      <th>gru</th>\n      <td>0.687500</td>\n      <td>0.697917</td>\n      <td>0.656250</td>\n      <td>0.729167</td>\n      <td>0.677083</td>\n    </tr>\n    <tr>\n      <th>lstm</th>\n      <td>0.625000</td>\n      <td>0.645833</td>\n      <td>0.583333</td>\n      <td>0.687500</td>\n      <td>0.645833</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        ochiai  tarantula     dstar   ochiai2     ample\nsrnn  0.635417   0.718750  0.614583  0.802083  0.604167\ngru   0.687500   0.697917  0.656250  0.729167  0.677083\nlstm  0.625000   0.645833  0.583333  0.687500  0.645833"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_per_me = pd.DataFrame.from_dict(dic_per_me_variant)\n",
    "display(df_per_me)\n",
    "np.savetxt('./stat_res_per_method.csv', df_per_me.values, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnistだけ効果量大で取り出せた場合 > 平均で勝った場合になってるのがまじでわからん\n",
    "平均を計算し直してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for me in method_names:\n",
    "  boot_list = np.zeros((10, 48, 6))\n",
    "  for bi in range(10):\n",
    "    pafl_path = f'./artifacts/pafl_res_fortest/boot_{bi}/{me}_pafl_res.csv'\n",
    "    boot_list[bi, :, :] = np.genfromtxt(pafl_path, delimiter=',', dtype='float').astype(np.float32)\n",
    "  boot_avg = np.nanmean(boot_list, axis=0)\n",
    "  # 保存\n",
    "  save_path = f'./artifacts/pafl_res_fortest/_boot_avg/{me}_pafl_res.csv'\n",
    "  os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "  np.savetxt(save_path, boot_avg, delimiter=',', fmt='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('conda': virtualenv)",
   "name": "python397jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}